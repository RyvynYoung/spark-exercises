{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Independent Lesson Work Through"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports for Spark - not this is the 'simple' import from the previous page\n",
    "# see Environment Setup for more complex import\n",
    "import pyspark\n",
    "\n",
    "spark = pyspark.sql.SparkSession.builder.getOrCreate()\n",
    "# Using .getOrCreate will only create a new spark session once. \n",
    "# Subsequent calls to that method will re-use the existing session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n</th>\n",
       "      <th>group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>c</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     n group\n",
       "0    0     b\n",
       "1    1     b\n",
       "2    2     c\n",
       "3    3     a\n",
       "4    4     c\n",
       "5    5     c\n",
       "6    6     a\n",
       "7    7     b\n",
       "8    8     a\n",
       "9    9     b\n",
       "10  10     b\n",
       "11  11     a\n",
       "12  12     b\n",
       "13  13     a\n",
       "14  14     b\n",
       "15  15     b\n",
       "16  16     c\n",
       "17  17     c\n",
       "18  18     a\n",
       "19  19     c"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now create a simple pandas df for comparision to Spark\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(456)\n",
    "\n",
    "pandas_dataframe = pd.DataFrame(\n",
    "    dict(n=np.arange(20), group=np.random.choice(list(\"abc\"), 20))\n",
    ")\n",
    "pandas_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[n: bigint, group: string]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# conver the pandas df to a Spark Df\n",
    "df = spark.createDataFrame(pandas_dataframe)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+\n",
      "|  n|group|\n",
      "+---+-----+\n",
      "|  0|    b|\n",
      "|  1|    b|\n",
      "|  2|    c|\n",
      "|  3|    a|\n",
      "|  4|    c|\n",
      "+---+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# to get Spark to actually show values\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[summary: string, n: string, group: string]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Spark version of describe\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+-----+\n",
      "|summary|                n|group|\n",
      "+-------+-----------------+-----+\n",
      "|  count|               20|   20|\n",
      "|   mean|              9.5| null|\n",
      "| stddev|5.916079783099616| null|\n",
      "|    min|                0|    a|\n",
      "|    max|               19|    c|\n",
      "+-------+-----------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# because it is Spark we have to explicitly show the describe\n",
    "df.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----+-----+----+---+----------+---+---+---+---+-------+\n",
      "|manufacturer|model|displ|year|cyl|     trans|drv|cty|hwy| fl|  class|\n",
      "+------------+-----+-----+----+---+----------+---+---+---+---+-------+\n",
      "|        audi|   a4|  1.8|1999|  4|  auto(l5)|  f| 18| 29|  p|compact|\n",
      "|        audi|   a4|  1.8|1999|  4|manual(m5)|  f| 21| 29|  p|compact|\n",
      "|        audi|   a4|  2.0|2008|  4|manual(m6)|  f| 20| 31|  p|compact|\n",
      "|        audi|   a4|  2.0|2008|  4|  auto(av)|  f| 21| 30|  p|compact|\n",
      "|        audi|   a4|  2.8|1999|  6|  auto(l5)|  f| 16| 26|  p|compact|\n",
      "+------------+-----+-----+----+---+----------+---+---+---+---+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# get a more robust dataset\n",
    "from pydataset import data\n",
    "\n",
    "mpg = spark.createDataFrame(data(\"mpg\"))\n",
    "mpg.show(5)\n",
    "# the (5) will show just 5 rows, change the value to see more/less"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Column<b'hwy'>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compare seeing a column to pandas\n",
    "mpg.hwy\n",
    "# in pandas this would return a series of the data in the column, Spark returns just a column object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+------------------+\n",
      "|hwy|cty|             model|\n",
      "+---+---+------------------+\n",
      "| 29| 18|                a4|\n",
      "| 29| 21|                a4|\n",
      "| 31| 20|                a4|\n",
      "| 30| 21|                a4|\n",
      "| 26| 16|                a4|\n",
      "| 26| 18|                a4|\n",
      "| 27| 18|                a4|\n",
      "| 26| 18|        a4 quattro|\n",
      "| 25| 16|        a4 quattro|\n",
      "| 28| 20|        a4 quattro|\n",
      "| 27| 19|        a4 quattro|\n",
      "| 25| 15|        a4 quattro|\n",
      "| 25| 17|        a4 quattro|\n",
      "| 25| 17|        a4 quattro|\n",
      "| 25| 15|        a4 quattro|\n",
      "| 24| 15|        a6 quattro|\n",
      "| 25| 17|        a6 quattro|\n",
      "| 23| 16|        a6 quattro|\n",
      "| 20| 14|c1500 suburban 2wd|\n",
      "| 15| 11|c1500 suburban 2wd|\n",
      "+---+---+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# to see the data use .select and .show() together, returns 20 rows\n",
    "mpg.select(mpg.hwy, mpg.cty, mpg.model).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Column<b'(hwy + 1)'>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Our column objects support a numer of operations, including the arithmetic operators\n",
    "mpg.hwy + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+\n",
      "|hwy|(hwy + 1)|\n",
      "+---+---------+\n",
      "| 29|       30|\n",
      "| 29|       30|\n",
      "| 31|       32|\n",
      "| 30|       31|\n",
      "| 26|       27|\n",
      "+---+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# To actually see this data, we'd need to select it and show the dataframe\n",
    "mpg.select(mpg.hwy, mpg.hwy + 1).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+\n",
      "|highway_mileage|\n",
      "+---------------+\n",
      "|             29|\n",
      "|             29|\n",
      "|             31|\n",
      "|             30|\n",
      "|             26|\n",
      "+---------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Once we have a column object, we can use the .alias method to rename it:\n",
    "mpg.select(mpg.hwy.alias(\"highway_mileage\")).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+----------------------+\n",
      "|highway_mileage|highway_mileage_halved|\n",
      "+---------------+----------------------+\n",
      "|             29|                  14.5|\n",
      "|             29|                  14.5|\n",
      "|             31|                  15.5|\n",
      "|             30|                  15.0|\n",
      "|             26|                  13.0|\n",
      "+---------------+----------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# we can also store column objects in variables and reference them\n",
    "col1 = mpg.hwy.alias(\"highway_mileage\")\n",
    "col2 = (mpg.hwy / 2).alias(\"highway_mileage_halved\")\n",
    "mpg.select(col1, col2).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercises\n",
    "Within your codeup-data-science directory, create a new repo named spark-exercises. This will be where you do your work for this module. Create a repository on GitHub with the same name, and link your local repository to GitHub.\n",
    "\n",
    "Save this work in your spark-exercises repo. Then add, commit, and push your changes.\n",
    "\n",
    "Create a jupyter notebook or python script named spark101 for this exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pydataset import data\n",
    "\n",
    "spark = pyspark.sql.SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Create a spark data frame that contains your favorite programming languages.\n",
    "\n",
    "- The name of the column should be language\n",
    "- View the schema of the dataframe\n",
    "- Output the shape of the dataframe\n",
    "- Show the first 5 records in the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create pandas dataframe by columns using dictionary-like object\n",
    "pd_df = pd.DataFrame({'language': ['Python', 'JavaScript', 'HTML', 'Java', 'C']})\n",
    "# convert the pandas df to a Spark df\n",
    "sp_df = spark.createDataFrame(pd_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- language: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# .printSchema()\n",
    "sp_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[summary: string, language: string]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, ['language'])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# output the shape of the df\n",
    "sp_df.count(), sp_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from Kwame\n",
    "def spark_shape(self):\n",
    "    return (self.count(), len(self.columns))\n",
    "pyspark.sql.dataframe.DataFrame.shape = spark_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|  language|\n",
      "+----------+\n",
      "|    Python|\n",
      "|JavaScript|\n",
      "|      HTML|\n",
      "|      Java|\n",
      "|         C|\n",
      "+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 1st 5 records\n",
    "sp_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Load the mpg dataset as a spark dataframe.\n",
    "\n",
    "- Create 1 column of output that contains a message like the one below:\n",
    "    - The 1999 audi a4 has a 4 cylinder engine.\n",
    "        - For each vehicle.\n",
    "\n",
    "- Transform the trans column so that it only contains either manual or auto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>manufacturer</th>\n",
       "      <th>model</th>\n",
       "      <th>displ</th>\n",
       "      <th>year</th>\n",
       "      <th>cyl</th>\n",
       "      <th>trans</th>\n",
       "      <th>drv</th>\n",
       "      <th>cty</th>\n",
       "      <th>hwy</th>\n",
       "      <th>fl</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>audi</td>\n",
       "      <td>a4</td>\n",
       "      <td>1.8</td>\n",
       "      <td>1999</td>\n",
       "      <td>4</td>\n",
       "      <td>auto(l5)</td>\n",
       "      <td>f</td>\n",
       "      <td>18</td>\n",
       "      <td>29</td>\n",
       "      <td>p</td>\n",
       "      <td>compact</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>audi</td>\n",
       "      <td>a4</td>\n",
       "      <td>1.8</td>\n",
       "      <td>1999</td>\n",
       "      <td>4</td>\n",
       "      <td>manual(m5)</td>\n",
       "      <td>f</td>\n",
       "      <td>21</td>\n",
       "      <td>29</td>\n",
       "      <td>p</td>\n",
       "      <td>compact</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>audi</td>\n",
       "      <td>a4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2008</td>\n",
       "      <td>4</td>\n",
       "      <td>manual(m6)</td>\n",
       "      <td>f</td>\n",
       "      <td>20</td>\n",
       "      <td>31</td>\n",
       "      <td>p</td>\n",
       "      <td>compact</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>audi</td>\n",
       "      <td>a4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2008</td>\n",
       "      <td>4</td>\n",
       "      <td>auto(av)</td>\n",
       "      <td>f</td>\n",
       "      <td>21</td>\n",
       "      <td>30</td>\n",
       "      <td>p</td>\n",
       "      <td>compact</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>audi</td>\n",
       "      <td>a4</td>\n",
       "      <td>2.8</td>\n",
       "      <td>1999</td>\n",
       "      <td>6</td>\n",
       "      <td>auto(l5)</td>\n",
       "      <td>f</td>\n",
       "      <td>16</td>\n",
       "      <td>26</td>\n",
       "      <td>p</td>\n",
       "      <td>compact</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  manufacturer model  displ  year  cyl       trans drv  cty  hwy fl    class\n",
       "1         audi    a4    1.8  1999    4    auto(l5)   f   18   29  p  compact\n",
       "2         audi    a4    1.8  1999    4  manual(m5)   f   21   29  p  compact\n",
       "3         audi    a4    2.0  2008    4  manual(m6)   f   20   31  p  compact\n",
       "4         audi    a4    2.0  2008    4    auto(av)   f   21   30  p  compact\n",
       "5         audi    a4    2.8  1999    6    auto(l5)   f   16   26  p  compact"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pandas df\n",
    "mpg_pd = data(\"mpg\")\n",
    "mpg_pd.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----+-----+----+---+----------+---+---+---+---+-------+\n",
      "|manufacturer|model|displ|year|cyl|     trans|drv|cty|hwy| fl|  class|\n",
      "+------------+-----+-----+----+---+----------+---+---+---+---+-------+\n",
      "|        audi|   a4|  1.8|1999|  4|  auto(l5)|  f| 18| 29|  p|compact|\n",
      "|        audi|   a4|  1.8|1999|  4|manual(m5)|  f| 21| 29|  p|compact|\n",
      "|        audi|   a4|  2.0|2008|  4|manual(m6)|  f| 20| 31|  p|compact|\n",
      "|        audi|   a4|  2.0|2008|  4|  auto(av)|  f| 21| 30|  p|compact|\n",
      "|        audi|   a4|  2.8|1999|  6|  auto(l5)|  f| 16| 26|  p|compact|\n",
      "+------------+-----+-----+----+---+----------+---+---+---+---+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# spark df\n",
    "mpg = spark.createDataFrame(data(\"mpg\"))\n",
    "mpg.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------------------+\n",
      "|Description                                  |\n",
      "+---------------------------------------------+\n",
      "|The 1999audia4has a 4 cylinder engine        |\n",
      "|The 1999audia4has a 4 cylinder engine        |\n",
      "|The 2008audia4has a 4 cylinder engine        |\n",
      "|The 2008audia4has a 4 cylinder engine        |\n",
      "|The 1999audia4has a 6 cylinder engine        |\n",
      "|The 1999audia4has a 6 cylinder engine        |\n",
      "|The 2008audia4has a 6 cylinder engine        |\n",
      "|The 1999audia4 quattrohas a 4 cylinder engine|\n",
      "|The 1999audia4 quattrohas a 4 cylinder engine|\n",
      "|The 2008audia4 quattrohas a 4 cylinder engine|\n",
      "+---------------------------------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import round, concat, sum, min, max, count, avg, mean\n",
    "from pyspark.sql.functions import lit\n",
    "\n",
    "#The 1999 audi a4 has a 4 cylinder engine\n",
    "mpg.select(concat(lit(\"The \"), mpg.year, mpg.manufacturer, mpg.model, \n",
    "                  lit(\"has a \"), mpg.cyl, lit(\" cylinder engine\")).alias(\"Description\")).show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------------------------------------------------+\n",
      "|     trans|CASE WHEN startswith(trans, a) THEN auto ELSE manual END|\n",
      "+----------+--------------------------------------------------------+\n",
      "|  auto(l5)|                                                    auto|\n",
      "|manual(m5)|                                                  manual|\n",
      "|manual(m6)|                                                  manual|\n",
      "|  auto(av)|                                                    auto|\n",
      "|  auto(l5)|                                                    auto|\n",
      "|manual(m5)|                                                  manual|\n",
      "|  auto(av)|                                                    auto|\n",
      "|manual(m5)|                                                  manual|\n",
      "|  auto(l5)|                                                    auto|\n",
      "|manual(m6)|                                                  manual|\n",
      "+----------+--------------------------------------------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import when\n",
    "# Transform the trans column so that it only contains either manual or auto.\n",
    "mpg.select(mpg.trans, when(mpg.trans.startswith(\"a\"), \"auto\").otherwise(\"manual\")).show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----+-----+----+---+------+---+---+---+---+-------+\n",
      "|manufacturer|model|displ|year|cyl| trans|drv|cty|hwy| fl|  class|\n",
      "+------------+-----+-----+----+---+------+---+---+---+---+-------+\n",
      "|        audi|   a4|  1.8|1999|  4|  auto|  f| 18| 29|  p|compact|\n",
      "|        audi|   a4|  1.8|1999|  4|manual|  f| 21| 29|  p|compact|\n",
      "|        audi|   a4|  2.0|2008|  4|manual|  f| 20| 31|  p|compact|\n",
      "|        audi|   a4|  2.0|2008|  4|  auto|  f| 21| 30|  p|compact|\n",
      "|        audi|   a4|  2.8|1999|  6|  auto|  f| 16| 26|  p|compact|\n",
      "|        audi|   a4|  2.8|1999|  6|manual|  f| 18| 26|  p|compact|\n",
      "+------------+-----+-----+----+---+------+---+---+---+---+-------+\n",
      "only showing top 6 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mpg = mpg.withColumn(\"trans\", when(mpg.trans.startswith(\"a\"), \"auto\").otherwise(\"manual\")).show(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Load the tips dataset as a spark dataframe.\n",
    "\n",
    "- What percentage of observations are smokers?\n",
    "- Create a column that contains the tip percentage\n",
    "- Calculate the average tip percentage for each combination of sex and smoker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+------+------+---+------+----+\n",
      "|total_bill| tip|   sex|smoker|day|  time|size|\n",
      "+----------+----+------+------+---+------+----+\n",
      "|     16.99|1.01|Female|    No|Sun|Dinner|   2|\n",
      "|     10.34|1.66|  Male|    No|Sun|Dinner|   3|\n",
      "|     21.01| 3.5|  Male|    No|Sun|Dinner|   3|\n",
      "|     23.68|3.31|  Male|    No|Sun|Dinner|   2|\n",
      "|     24.59|3.61|Female|    No|Sun|Dinner|   4|\n",
      "+----------+----+------+------+---+------+----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tips = spark.createDataFrame(data(\"tips\"))\n",
    "tips.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "244 rows 7 columns\n"
     ]
    }
   ],
   "source": [
    "# What percentage of observations are smokers?\n",
    "print(tips.count(), \"rows\", len(tips.columns), \"columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+\n",
      "|smoker|count|\n",
      "+------+-----+\n",
      "|    No|  151|\n",
      "|   Yes|   93|\n",
      "+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# What percentage of observations are smokers?\n",
    "tips.groupBy(\"smoker\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.38114754098360654"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What percentage of observations are smokers?\n",
    "tips.filter(tips.smoker == \"Yes\").count()/tips.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a column that contains the tip percentage\n",
    "tips = tips.withColumn('tip_percentage', (tips.tip/tips.total_bill))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------------------+-------------------+\n",
      "|   sex|                No|                Yes|\n",
      "+------+------------------+-------------------+\n",
      "|Female|0.1569209707691836|0.18215035269941032|\n",
      "|  Male|0.1606687151291298|0.15277117520248512|\n",
      "+------+------------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculate the average tip percentage for each combination of sex and smoker.\n",
    "# tips.show()\n",
    "tips.groupby(\"sex\").pivot(\"smoker\").mean(\"tip_percentage\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Use the seattle weather dataset referenced in the lesson to answer the questions below.\n",
    "\n",
    "- Convert the temperatures to farenheight.\n",
    "- Which month has the most rain, on average?\n",
    "- Which year was the windiest?\n",
    "- What is the most frequent type of weather in January?\n",
    "- What is the average high and low tempurature on sunny days in July in 2013 and 2014?\n",
    "- What percentage of days were rainy in q3 of 2015?\n",
    "- For each year, find what percentage of days it rained (had non-zero precipitation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------+--------+--------+----+-------+\n",
      "|      date|precipitation|temp_max|temp_min|wind|weather|\n",
      "+----------+-------------+--------+--------+----+-------+\n",
      "|2012-01-01|          0.0|    12.8|     5.0| 4.7|drizzle|\n",
      "|2012-01-02|         10.9|    10.6|     2.8| 4.5|   rain|\n",
      "|2012-01-03|          0.8|    11.7|     7.2| 2.3|   rain|\n",
      "|2012-01-04|         20.3|    12.2|     5.6| 4.7|   rain|\n",
      "|2012-01-05|          1.3|     8.9|     2.8| 6.1|   rain|\n",
      "|2012-01-06|          2.5|     4.4|     2.2| 2.2|   rain|\n",
      "+----------+-------------+--------+--------+----+-------+\n",
      "only showing top 6 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from vega_datasets import data\n",
    "\n",
    "weather = data.seattle_weather().assign(date=lambda df: df.date.astype(str))\n",
    "weather = spark.createDataFrame(weather)\n",
    "weather.show(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the temperatures to farenheight.\n",
    "# formula to convert to farenheight = (0°C × 9/5) + 32 = 32°F\n",
    "weather = weather.withColumn('temp_max', (round(weather.temp_max * (9/5) + 32, 1)))\n",
    "weather = weather.withColumn('temp_min', (round(weather.temp_min * (9/5) + 32, 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------+--------+--------+----+-------+\n",
      "|      date|precipitation|temp_max|temp_min|wind|weather|\n",
      "+----------+-------------+--------+--------+----+-------+\n",
      "|2012-01-01|          0.0|    55.0|    41.0| 4.7|drizzle|\n",
      "|2012-01-02|         10.9|    51.1|    37.0| 4.5|   rain|\n",
      "|2012-01-03|          0.8|    53.1|    45.0| 2.3|   rain|\n",
      "|2012-01-04|         20.3|    54.0|    42.1| 4.7|   rain|\n",
      "|2012-01-05|          1.3|    48.0|    37.0| 6.1|   rain|\n",
      "|2012-01-06|          2.5|    39.9|    36.0| 2.2|   rain|\n",
      "|2012-01-07|          0.0|    45.0|    37.0| 2.3|   rain|\n",
      "|2012-01-08|          0.0|    50.0|    37.0| 2.0|    sun|\n",
      "|2012-01-09|          4.3|    48.9|    41.0| 3.4|   rain|\n",
      "|2012-01-10|          1.0|    43.0|    33.1| 3.4|   rain|\n",
      "|2012-01-11|          0.0|    43.0|    30.0| 5.1|    sun|\n",
      "|2012-01-12|          0.0|    43.0|    28.9| 1.9|    sun|\n",
      "|2012-01-13|          0.0|    41.0|    27.0| 1.3|    sun|\n",
      "|2012-01-14|          4.1|    39.9|    33.1| 5.3|   snow|\n",
      "|2012-01-15|          5.3|    34.0|    26.1| 3.2|   snow|\n",
      "|2012-01-16|          2.5|    35.1|    27.0| 5.0|   snow|\n",
      "|2012-01-17|          8.1|    37.9|    32.0| 5.6|   snow|\n",
      "|2012-01-18|         19.8|    32.0|    27.0| 5.0|   snow|\n",
      "|2012-01-19|         15.2|    30.0|    27.0| 1.6|   snow|\n",
      "|2012-01-20|         13.5|    45.0|    30.0| 2.3|   snow|\n",
      "+----------+-------------+--------+--------+----+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "weather.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "filter expected 2 arguments, got 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-e82df47b853f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Which month has the most rain, on average?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# mpg.groupBy(mpg.cyl).agg(avg(mpg.cty), avg(mpg.hwy)).show()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mweather\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupBy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'date'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweather\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweather\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'rain'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweather\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweather\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: filter expected 2 arguments, got 1"
     ]
    }
   ],
   "source": [
    "# Which month has the most rain, on average?\n",
    "# mpg.groupBy(mpg.cyl).agg(avg(mpg.cty), avg(mpg.hwy)).show()\n",
    "weather.groupBy('date').agg(count(filter(weather.weather == 'rain'), count(weather.weather))).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
